{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K6EK4SyEBTc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Loading the uploaded file\n",
        "data = pd.read_csv('data/Hotel_Reviews.csv')\n",
        "\n",
        "# Printing the first few rows to confirm it's loaded\n",
        "print(data.head())\n",
        "print(data.info())"
      ],
      "metadata": {
        "id": "JFue9qhMKOrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning & Pre-Processing\n",
        "\n",
        "# Dropping unnecessary columns to reduce noise\n",
        "data_clean = data.drop([\n",
        "    'Unnamed: 0', 'query', 'google_id', 'place_id',\n",
        "    'location_link', 'reviews_link', 'author_link',\n",
        "    'author_image', 'review_img_url', 'review_img_urls',\n",
        "    'review_photo_ids', 'review_link', 'reviews_id'\n",
        "], axis=1)\n",
        "\n",
        "# Converting timestamp columns to datetime format\n",
        "data_clean['review_datetime_utc'] = pd.to_datetime(data_clean['review_datetime_utc'])\n",
        "\n",
        "# Filling missing review text with a placeholder\n",
        "data_clean.loc[:, 'review_text'] = data_clean['review_text'].fillna('No review provided')\n",
        "\n",
        "# Checking for any remaining missing values\n",
        "print(data_clean.isnull().sum())\n",
        "print(data_clean.head())\n"
      ],
      "metadata": {
        "id": "xqJ6Rly5MBOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values\n",
        "\n",
        "# Converting float columns to string and fill missing values with 'Unknown'\n",
        "columns_to_convert = ['review_questions_Rooms', 'review_questions_Service', 'review_questions_Location']\n",
        "data_clean[columns_to_convert] = data_clean[columns_to_convert].astype(str).fillna('Unknown')\n",
        "\n",
        "# Using .loc to fill other missing values safely\n",
        "data_clean.loc[:, 'owner_answer'] = data_clean['owner_answer'].fillna('No Response')\n",
        "data_clean.loc[:, 'owner_answer_timestamp'] = data_clean['owner_answer_timestamp'].fillna(0)\n",
        "data_clean.loc[:, 'review_questions_Trip type'] = data_clean['review_questions_Trip type'].fillna('Unknown')\n",
        "data_clean.loc[:, 'review_questions_Travel group'] = data_clean['review_questions_Travel group'].fillna('Unknown')\n",
        "\n",
        "# Verifying that all missing values are handled\n",
        "print(data_clean.isnull().sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "uhPbjWkMNPrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "# Step 1: Distribution of Review Ratings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the distribution of review ratings with rotated x-axis labels\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=data_clean, x='review_rating')\n",
        "plt.title('Distribution of Review Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)  # Rotate labels 45 degrees for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v8bcHauJnbxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Analyzing Average Rating by Trip Type\n",
        "\n",
        "# Grouping by trip type and calculating the average rating\n",
        "trip_type_ratings = data_clean.groupby('review_questions_Trip type')['review_rating'].mean()\n",
        "\n",
        "# Plotting the results\n",
        "trip_type_ratings.plot(kind='bar', title='Average Rating by Trip Type', figsize=(10, 5))\n",
        "plt.xlabel('Trip Type')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BijdT_x2oxsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Relationship Between Service Quality and Rating\n",
        "\n",
        "# Plotting the relationship between service quality and review rating\n",
        "sns.boxplot(data=data_clean, x='review_questions_Service', y='review_rating')\n",
        "plt.title('Impact of Service Quality on Ratings')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tFkaBBGapHB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Trends in Ratings Over Time\n",
        "\n",
        "# Grouping by review date to analyze trends in ratings over time\n",
        "data_clean.set_index('review_datetime_utc').resample('ME')['review_rating'].mean().plot(figsize=(10, 5))\n",
        "plt.title('Trend of Average Ratings Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nt1iV300pQka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: WordCloud of Positive and Negative Reviews\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# WordCloud for Positive Reviews:\n",
        "\n",
        "# Concatenating all positive reviews\n",
        "positive_reviews = ' '.join(data_clean[data_clean['review_rating'] >= 4]['review_text'])\n",
        "\n",
        "# Generating the WordCloud\n",
        "wordcloud = WordCloud(width=800, height=400).generate(positive_reviews)\n",
        "\n",
        "# Plotting the WordCloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('WordCloud of Positive Reviews')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OX7c5fRspyz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WordCloud for Negative Reviews:\n",
        "\n",
        "# Concatenating all negative reviews\n",
        "negative_reviews = ' '.join(data_clean[data_clean['review_rating'] <= 2]['review_text'])\n",
        "\n",
        "# Generating the WordCloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='black').generate(negative_reviews)\n",
        "\n",
        "# Plotting the WordCloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('WordCloud of Negative Reviews')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j_t_vxGmqKtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis with VADER (Valence Aware Dictionary for Sentiment Reasoning)\n",
        "\n",
        "# Step 1: Installing the VADER Sentiment Analysis Tool\n",
        "\n",
        "# Installing NLTK\n",
        "!pip install nltk\n",
        "\n",
        "# Importing the VADER Sentiment Analyzer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "# Downloading the VADER lexicon\n",
        "nltk.download('vader_lexicon')\n"
      ],
      "metadata": {
        "id": "JqNDavsjsQVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Applying VADER Sentiment Analysis to Review Text\n",
        "\n",
        "# Initializing the Sentiment Analyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Defining a function to classify sentiment based on the compound score\n",
        "def get_sentiment(score):\n",
        "    if score >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif score <= -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Applying VADER to calculate sentiment scores for each review\n",
        "data_clean['sentiment_score'] = data_clean['review_text'].apply(lambda x: sid.polarity_scores(x)['compound'])\n",
        "\n",
        "# Classifying sentiment based on score\n",
        "data_clean['sentiment'] = data_clean['sentiment_score'].apply(get_sentiment)\n",
        "\n",
        "# Displaying the sentiment distribution\n",
        "print(data_clean['sentiment'].value_counts())\n",
        "\n",
        "# Plotting the sentiment distribution\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.countplot(data=data_clean, x='sentiment')\n",
        "plt.title('Sentiment Distribution of Reviews')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TovIqpf2soMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarizing Reviews with a Gen AI Model\n",
        "\n",
        "# Step 1: Installing the Hugging Face Transformers Library\n",
        "!pip install transformers\n",
        "\n",
        "# Step 2: Loading a Summarization Model\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Step 3: Summarizing Sample Reviews\n",
        "# Selecting a few sample reviews for summarization\n",
        "sample_reviews = data_clean[data_clean['review_text'].str.len() > 200]['review_text'].sample(5)\n",
        "\n",
        "# Summarizing each review\n",
        "for i, review in enumerate(sample_reviews):\n",
        "    print(f\"Original Review {i+1}:\")\n",
        "    print(review)\n",
        "    summary = summarizer(review, max_length=50, min_length=10, do_sample=False)[0]['summary_text']\n",
        "    print(\"\\nSummarized Review:\")\n",
        "    print(summary)\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ]
